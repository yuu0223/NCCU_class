{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6ZHOucvOOza"
      },
      "source": [
        "# Naive Bayes Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uK8D8UDUCZlc",
        "outputId": "5e4eda93-f702-4740-b576-2419c5d2412e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import movie_reviews\n",
        "nltk.download(\"movie_reviews\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyfLD0SRChBr",
        "outputId": "e13948d6-a18c-4a0a-afb5-0517679df7d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['plot', ':', 'two', 'teen', 'couples', 'go', 'to', 'a', 'church', 'party', ',', 'drink', 'and', 'then', 'drive', '.', 'they', 'get', 'into', 'an', 'accident', '.', 'one', 'of', 'the', 'guys', 'dies', ',', 'but', 'his', 'girlfriend', 'continues', 'to', 'see', 'him', 'in', 'her', 'life', ',', 'and', 'has', 'nightmares', '.', 'what', \"'\", 's', 'the', 'deal', '?', 'watch', 'the', 'movie', 'and', '\"', 'sorta', '\"', 'find', 'out', '.', '.', '.', 'critique', ':', 'a', 'mind', '-', 'fuck', 'movie', 'for', 'the', 'teen', 'generation', 'that', 'touches', 'on', 'a', 'very', 'cool', 'idea', ',', 'but', 'presents', 'it', 'in', 'a', 'very', 'bad', 'package', '.', 'which', 'is', 'what', 'makes', 'this', 'review', 'an', 'even', 'harder', 'one', 'to', 'write', ',', 'since', 'i', 'generally', 'applaud', 'films', 'which', 'attempt', 'to', 'break', 'the', 'mold', ',', 'mess', 'with', 'your', 'head', 'and', 'such', '(', 'lost', 'highway', '&', 'memento', ')', ',', 'but', 'there', 'are', 'good', 'and', 'bad', 'ways', 'of', 'making', 'all', 'types', 'of', 'films', ',', 'and', 'these', 'folks', 'just', 'didn', \"'\", 't', 'snag', 'this', 'one', 'correctly', '.', 'they', 'seem', 'to', 'have', 'taken', 'this', 'pretty', 'neat', 'concept', ',', 'but', 'executed', 'it', 'terribly', '.', 'so', 'what', 'are', 'the', 'problems', 'with', 'the', 'movie', '?', 'well', ',', 'its', 'main', 'problem', 'is', 'that', 'it', \"'\", 's', 'simply', 'too', 'jumbled', '.', 'it', 'starts', 'off', '\"', 'normal', '\"', 'but', 'then', 'downshifts', 'into', 'this', '\"', 'fantasy', '\"', 'world', 'in', 'which', 'you', ',', 'as', 'an', 'audience', 'member', ',', 'have', 'no', 'idea', 'what', \"'\", 's', 'going', 'on', '.', 'there', 'are', 'dreams', ',', 'there', 'are', 'characters', 'coming', 'back', 'from', 'the', 'dead', ',', 'there', 'are', 'others', 'who', 'look', 'like', 'the', 'dead', ',', 'there', 'are', 'strange', 'apparitions', ',', 'there', 'are', 'disappearances', ',', 'there', 'are', 'a', 'looooot', 'of', 'chase', 'scenes', ',', 'there', 'are', 'tons', 'of', 'weird', 'things', 'that', 'happen', ',', 'and', 'most', 'of', 'it', 'is', 'simply', 'not', 'explained', '.', 'now', 'i', 'personally', 'don', \"'\", 't', 'mind', 'trying', 'to', 'unravel', 'a', 'film', 'every', 'now', 'and', 'then', ',', 'but', 'when', 'all', 'it', 'does', 'is', 'give', 'me', 'the', 'same', 'clue', 'over', 'and', 'over', 'again', ',', 'i', 'get', 'kind', 'of', 'fed', 'up', 'after', 'a', 'while', ',', 'which', 'is', 'this', 'film', \"'\", 's', 'biggest', 'problem', '.', 'it', \"'\", 's', 'obviously', 'got', 'this', 'big', 'secret', 'to', 'hide', ',', 'but', 'it', 'seems', 'to', 'want', 'to', 'hide', 'it', 'completely', 'until', 'its', 'final', 'five', 'minutes', '.', 'and', 'do', 'they', 'make', 'things', 'entertaining', ',', 'thrilling', 'or', 'even', 'engaging', ',', 'in', 'the', 'meantime', '?', 'not', 'really', '.', 'the', 'sad', 'part', 'is', 'that', 'the', 'arrow', 'and', 'i', 'both', 'dig', 'on', 'flicks', 'like', 'this', ',', 'so', 'we', 'actually', 'figured', 'most', 'of', 'it', 'out', 'by', 'the', 'half', '-', 'way', 'point', ',', 'so', 'all', 'of', 'the', 'strangeness', 'after', 'that', 'did', 'start', 'to', 'make', 'a', 'little', 'bit', 'of', 'sense', ',', 'but', 'it', 'still', 'didn', \"'\", 't', 'the', 'make', 'the', 'film', 'all', 'that', 'more', 'entertaining', '.', 'i', 'guess', 'the', 'bottom', 'line', 'with', 'movies', 'like', 'this', 'is', 'that', 'you', 'should', 'always', 'make', 'sure', 'that', 'the', 'audience', 'is', '\"', 'into', 'it', '\"', 'even', 'before', 'they', 'are', 'given', 'the', 'secret', 'password', 'to', 'enter', 'your', 'world', 'of', 'understanding', '.', 'i', 'mean', ',', 'showing', 'melissa', 'sagemiller', 'running', 'away', 'from', 'visions', 'for', 'about', '20', 'minutes', 'throughout', 'the', 'movie', 'is', 'just', 'plain', 'lazy', '!', '!', 'okay', ',', 'we', 'get', 'it', '.', '.', '.', 'there', 'are', 'people', 'chasing', 'her', 'and', 'we', 'don', \"'\", 't', 'know', 'who', 'they', 'are', '.', 'do', 'we', 'really', 'need', 'to', 'see', 'it', 'over', 'and', 'over', 'again', '?', 'how', 'about', 'giving', 'us', 'different', 'scenes', 'offering', 'further', 'insight', 'into', 'all', 'of', 'the', 'strangeness', 'going', 'down', 'in', 'the', 'movie', '?', 'apparently', ',', 'the', 'studio', 'took', 'this', 'film', 'away', 'from', 'its', 'director', 'and', 'chopped', 'it', 'up', 'themselves', ',', 'and', 'it', 'shows', '.', 'there', 'might', \"'\", 've', 'been', 'a', 'pretty', 'decent', 'teen', 'mind', '-', 'fuck', 'movie', 'in', 'here', 'somewhere', ',', 'but', 'i', 'guess', '\"', 'the', 'suits', '\"', 'decided', 'that', 'turning', 'it', 'into', 'a', 'music', 'video', 'with', 'little', 'edge', ',', 'would', 'make', 'more', 'sense', '.', 'the', 'actors', 'are', 'pretty', 'good', 'for', 'the', 'most', 'part', ',', 'although', 'wes', 'bentley', 'just', 'seemed', 'to', 'be', 'playing', 'the', 'exact', 'same', 'character', 'that', 'he', 'did', 'in', 'american', 'beauty', ',', 'only', 'in', 'a', 'new', 'neighborhood', '.', 'but', 'my', 'biggest', 'kudos', 'go', 'out', 'to', 'sagemiller', ',', 'who', 'holds', 'her', 'own', 'throughout', 'the', 'entire', 'film', ',', 'and', 'actually', 'has', 'you', 'feeling', 'her', 'character', \"'\", 's', 'unraveling', '.', 'overall', ',', 'the', 'film', 'doesn', \"'\", 't', 'stick', 'because', 'it', 'doesn', \"'\", 't', 'entertain', ',', 'it', \"'\", 's', 'confusing', ',', 'it', 'rarely', 'excites', 'and', 'it', 'feels', 'pretty', 'redundant', 'for', 'most', 'of', 'its', 'runtime', ',', 'despite', 'a', 'pretty', 'cool', 'ending', 'and', 'explanation', 'to', 'all', 'of', 'the', 'craziness', 'that', 'came', 'before', 'it', '.', 'oh', ',', 'and', 'by', 'the', 'way', ',', 'this', 'is', 'not', 'a', 'horror', 'or', 'teen', 'slasher', 'flick', '.', '.', '.', 'it', \"'\", 's', 'just', 'packaged', 'to', 'look', 'that', 'way', 'because', 'someone', 'is', 'apparently', 'assuming', 'that', 'the', 'genre', 'is', 'still', 'hot', 'with', 'the', 'kids', '.', 'it', 'also', 'wrapped', 'production', 'two', 'years', 'ago', 'and', 'has', 'been', 'sitting', 'on', 'the', 'shelves', 'ever', 'since', '.', 'whatever', '.', '.', '.', 'skip', 'it', '!', 'where', \"'\", 's', 'joblo', 'coming', 'from', '?', 'a', 'nightmare', 'of', 'elm', 'street', '3', '(', '7', '/', '10', ')', '-', 'blair', 'witch', '2', '(', '7', '/', '10', ')', '-', 'the', 'crow', '(', '9', '/', '10', ')', '-', 'the', 'crow', ':', 'salvation', '(', '4', '/', '10', ')', '-', 'lost', 'highway', '(', '10', '/', '10', ')', '-', 'memento', '(', '10', '/', '10', ')', '-', 'the', 'others', '(', '9', '/', '10', ')', '-', 'stir', 'of', 'echoes', '(', '8', '/', '10', ')'] neg\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict, Counter\n",
        "import math\n",
        "import random\n",
        "\n",
        "train_X, train_Y = [], []\n",
        "test_X, test_Y = [], []\n",
        "\n",
        "random.seed(0)\n",
        "for polarity in movie_reviews.categories():\n",
        "    for fid in movie_reviews.fileids(polarity):\n",
        "        if random.randrange(5) == 0:\n",
        "            test_X.append([w for w in movie_reviews.words(fid)])\n",
        "            test_Y.append(polarity)\n",
        "        else:\n",
        "            train_X.append([w for w in movie_reviews.words(fid)])\n",
        "            train_Y.append(polarity)\n",
        "\n",
        "print(train_X[0], train_Y[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TiSvHHAhy6H"
      },
      "source": [
        "## Model Construction\n",
        "\n",
        "$\\bar{y} = \\text{arg}\\max_{y \\in \\mathbf{y}} P(y|x) = \\text{arg}\\max_{y \\in \\mathbf{y}} P(y) \\prod_{i=1}^n \\frac{P(x_i|y)}{P(x_i)} = \\text{arg}\\max_{y \\in \\mathbf{y}} P(y) \\prod_{i=1}^n P(x_i|y)$\n",
        "\n",
        "$P(x_i|y)=\\frac{C(x_i, y) + k}{C(y) + |\\mathbf{y}| \\times k}$\n",
        "\n",
        "$\\bar{y} = \\textrm{arg} \\max_{y \\in \\mathbf{y}} \\log P(y) + \\sum_{i=1}^n \\log \\frac{C(x_i, y) + k}{C(y) + k|\\mathbf{y}|}$\n",
        "\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fobAkWURDr6L",
        "outputId": "97ba183a-7b45-4369-8214-4619c8fff916"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "import spacy\n",
        "\n",
        "\n",
        "class NaiveBayesClassifier:\n",
        "    def __init__(self, k=0.9, min_word_freq=32):\n",
        "        # k為smoothing features\n",
        "        self.k = k\n",
        "        self.min_word_freq = min_word_freq\n",
        "        self.features = set()\n",
        "        # defaultdict可以用來設定不同的存放容器 e.g. defaultdict(list) => [1,2,3] / defaultdict(set) => {1,2,3}\n",
        "        self.class_feature_counts = defaultdict(Counter)\n",
        "        self.class_counts = Counter()\n",
        "        self.total = 0\n",
        "        # stop words和標點符號\n",
        "        self.nlp = spacy.load('en_core_web_sm')\n",
        "        self.stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
        "        sign_list = [\";\", \",\", \".\", \"~\", \":\", \"-\", \"(\", \")\", \"%\", \"#\", \"$\", \"!\", \"/\", \"?\", \"=\", \"+\", \"&\", \"--\", \"'\", '\"', '`']\n",
        "        for sign in sign_list:\n",
        "          self.stop_words.add(sign)\n",
        "        # 詞形還原、詞幹提取\n",
        "        self.stemmer = PorterStemmer()\n",
        "        self.lemmatizer = WordNetLemmatizer()\n",
        "        # 詞頻計算\n",
        "        self.word_counts = Counter()\n",
        "\n",
        "\n",
        "    def preprocess(self, tokens):\n",
        "        tokens = [token.lower() for token in tokens]\n",
        "        tokens = [self.lemmatizer.lemmatize(token) for token in tokens]\n",
        "        # tokens = [token for token in tokens if token not in self.stop_words]\n",
        "        # tokens = [self.stemmer.stem(token) for token in tokens]\n",
        "\n",
        "        return tokens\n",
        "\n",
        "\n",
        "    def train(self, train_X, train_Y):\n",
        "        # tokens = \"字\" / label = \"neg\" or \"pos\"\n",
        "        for tokens, label in zip(train_X, train_Y):\n",
        "            tokens = self.preprocess(tokens)\n",
        "            #更新每個樣本類別出現的次數\n",
        "            self.class_counts[label] += 1\n",
        "            #更新總訓練樣本數\n",
        "            self.total += 1\n",
        "\n",
        "            self.word_counts.update(tokens)\n",
        "\n",
        "            for token in set(tokens):\n",
        "                self.features.add(token)\n",
        "                self.class_feature_counts[label][token] += 1\n",
        "        # 詞頻篩選，刪除太少出現的\n",
        "        self.features = {word for word in self.features if self.word_counts[word] >= self.min_word_freq }\n",
        "\n",
        "\n",
        "    def probabilities(self, token):\n",
        "        probs = {}\n",
        "        for cls, cls_cnt in self.class_counts.items():\n",
        "            probs[cls] = (self.class_feature_counts[cls][token] + self.k) / (cls_cnt + len(self.class_counts) * self.k)\n",
        "        return probs\n",
        "\n",
        "    def predict(self, tokens):\n",
        "        tokens = set(tokens)\n",
        "        tokens = self.preprocess(tokens)\n",
        "        log_probs = Counter()\n",
        "        for cls, cls_cnt in self.class_counts.items():\n",
        "            log_probs[cls] = math.log(cls_cnt / self.total)\n",
        "        for token in self.features:\n",
        "              probs = self.probabilities(token)\n",
        "              if token in tokens:\n",
        "                  for cls, prob in probs.items():\n",
        "                      log_probs[cls] += math.log(prob)\n",
        "              else:\n",
        "                  for cls, prob in probs.items():\n",
        "                      log_probs[cls] += math.log(1.0 - prob)\n",
        "        # Return the argmax of log_probs and all log_probs\n",
        "        return max(log_probs, key=log_probs.get), log_probs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GE_Ht04wh3Tc"
      },
      "source": [
        "## Using the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5rdZQ-aJhtld"
      },
      "outputs": [],
      "source": [
        "model = NaiveBayesClassifier()\n",
        "model.train(train_X, train_Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeH93xRFZ1EF",
        "outputId": "60f76f42-b72b-45ad-dc47-27d9292cdb5e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('pos', Counter({'neg': -433.239532854839, 'pos': -426.4539894608389}))"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Taken from https://www.imdb.com/review/rw0990793/?ref_=tt_urv\n",
        "review = \"\"\"A whimsical, often spectacular view of a future in which advances in technology dominate the world. It is well shot and although slow-moving it is intense and enjoyable throughout. The featuring of classical music to establish atmosphere works brilliantly; it provides a feeling of awe, mystery and intrigue  the same aura that Walt Disney worked in creating 'Fantasia'. The special effects, both sound and visual, are still spellbinding by the standards of today's technology. Aside from the technical pluses of the film, it stands strong as it is one of not many films out there that has something important to say about humankind, and where the human race is heading in terms of our increasing reliance on machines and our unquenchable thirst to discover. Despite an ending that is hard to understand, it is even harder to overlook this film a true cinema classic.\"\"\"\n",
        "\n",
        "model.predict(word_tokenize(review))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1lkFRJ0FKbc",
        "outputId": "9d7387f0-5c63-4f78-f4e8-db9da678c3ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "362 / 422 = 0.85782\n"
          ]
        }
      ],
      "source": [
        "correct, total = 0, 0\n",
        "\n",
        "for x, y in zip(test_X, test_Y):\n",
        "    prediction, _ = model.predict(x)\n",
        "    if prediction == y:\n",
        "        correct += 1\n",
        "    total += 1\n",
        "\n",
        "print(\"%d / %d = %g\" % (correct, total, correct / total))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmqZUqeTgjzW"
      },
      "source": [
        "## Exploring important features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xofcbwlXgluq",
        "outputId": "7bee2156-20fd-44e2-844c-52d017a921da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['outstanding', 'gattaca', 'mulan', 'wonderfully', 'refreshing', 'finest', 'guido', 'ordell', 'german', 'damon', 'coen', 'jedi', 'breathtaking', 'beautifully', 'religion', 'obi', 'lebowski', 'fashioned', 'superb', 'anger', 'politics', 'ordinary', 'shrek', 'fargo', 'flawless', 'homer', 'flynt', 'pulp', 'era', 'controversial']\n",
            "['schumacher', 'ludicrous', 'turkey', 'henstridge', 'welles', 'poorly', 'krippendorf', 'seagal', 'idiotic', 'uninspired', 'inept', 'uninteresting', 'sat', 'awful', 'unfunny', 'waste', 'wasted', 'natasha', 'lame', 'idiot', 'ridiculous', 'worst', 'pointless', 'stupid', 'random', 'bland', 'badly', 'mess', 'alicia', 'jolie']\n"
          ]
        }
      ],
      "source": [
        "def prob_class_given_feature(feature, cls, model):\n",
        "    probs = model.probabilities(feature)\n",
        "    return probs[cls] / sum(probs.values())\n",
        "\n",
        "print(sorted(model.features, key=lambda t: prob_class_given_feature(t, \"pos\", model), reverse=True)[:30])\n",
        "print(sorted(model.features, key=lambda t: prob_class_given_feature(t, \"neg\", model), reverse=True)[:30])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "h2WRZXh5nrk7"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
